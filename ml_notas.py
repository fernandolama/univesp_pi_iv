import streamlit as st
import numpy as np
import pandas as pd
import plotly.express as px
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN, KMeans
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestRegressor
from minisom import MiniSom

def clusters_anglo_liceu():
    # ========================

    # Carregar dataset

    # ========================

    @st.cache_data
    def carregar_dados():
        df = pd.read_csv("data/notas_colegio_teste.csv", sep=";", encoding="latin1")
        return df

    df = carregar_dados()
    st.write("### Dataset Carregado", df.head())

    # ========================

    # Sele√ß√£o de colunas num√©ricas

    # ========================

    colunas_numericas = df.select_dtypes(include=["int64", "float64"])
    st.write("Colunas num√©ricas dispon√≠veis:", colunas_numericas.columns.tolist())

    colunas_escolhidas = st.multiselect(
    "Selecione as colunas para an√°lise",
    colunas_numericas.columns.tolist(),
    default=colunas_numericas.columns.tolist()[:2]
    )

    if len(colunas_escolhidas) >= 2:
        # Preparar dados
        df_filtrado = df[colunas_escolhidas].dropna().copy()
        X_scaled = StandardScaler().fit_transform(df_filtrado)

        # ============================== 
        # Estat√≠stica descritiva simples 
        # ============================== 
        st.subheader("üìä Estat√≠stica Descritiva") 
        st.write(colunas_numericas.describe()) 
        
        # Maiores e menores notas por disciplina 
        maiores = colunas_numericas.max().sort_values(ascending=False) 
        menores = colunas_numericas.min().sort_values(ascending=True) 
        st.write("### Maiores notas por disciplina", maiores) 
        st.write("### Menores notas por disciplina", menores)

        # ============================== 
        # RandomForest - Import√¢ncia das disciplinas 
        # ============================== 
        st.subheader("üå≤ RandomForest - Import√¢ncia das disciplinas") 
        # Seleciona apenas colunas num√©ricas antes de calcular a m√©dia
        colunas_notas = df[[
            "nota_ciencias_natureza",
            "nota_ciencias_humanas",
            "nota_linguagens_codigos",
            "nota_matematica",
            "nota_redacao"
        ]].dropna()
        y = colunas_notas.mean(axis=1) # m√©dia geral como "alvo" 
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_scaled = StandardScaler().fit_transform(colunas_notas)
        rf.fit(rf_scaled, y) 
        importancia = pd.Series(rf.feature_importances_, index=colunas_notas.columns)
        importancia = importancia.sort_values(ascending=True) 
        
        fig_importancia = px.bar(
            importancia, 
            orientation="h", 
            title="Import√¢ncia das disciplinas para o desempenho geral" 
        )
        
        st.plotly_chart(fig_importancia, use_container_width=True)

        # Explica√ß√£o textual sobre o Random Forest
        st.info(
            "üå≤ **Interpreta√ß√£o do algoritmo Random Forest:**\n"
            "- O Random Forest √© um modelo de aprendizado supervisionado baseado em m√∫ltiplas √°rvores de decis√£o, usadas em conjunto para realizar previs√µes mais robustas e reduzir o risco de overfitting.\n"
            "- Cada √°rvore toma decis√µes sobre o desempenho dos alunos com base nas notas das disciplinas, e o modelo final combina essas √°rvores para encontrar padr√µes consistentes.\n"
            "- Uma das principais sa√≠das da Random Forest √© a **import√¢ncia das vari√°veis**, que indica quanto cada disciplina contribui para explicar o desempenho geral.\n"
            "- Disciplinas com maior import√¢ncia t√™m maior peso na diferencia√ß√£o dos resultados entre alunos.\n"
            "- Por exemplo, se a nota de Matem√°tica aparece como a vari√°vel mais importante, isso sugere que ela √© um bom preditor do desempenho global.\n"
            "- Essa an√°lise √© √∫til para identificar **as √°reas que mais influenciam o sucesso dos estudantes**, ajudando a priorizar a√ß√µes pedag√≥gicas e interven√ß√µes espec√≠ficas."
        )

    
        # ============================== 
        # KMeans - Agrupamento de alunos 
        # ============================== 
        st.subheader("ü§ñ KMeans - Agrupamento")
        n_clusters = st.slider("N√∫mero de clusters (K)", 2, 10, 3) 
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10) 
        clusters = kmeans.fit_predict(X_scaled) 
        df["Cluster_KMeans"] = -1 
        df.loc[df_filtrado.index, "Cluster_KMeans"] = clusters.astype(str) 
        fig_clusters = px.scatter( 
            df_filtrado, 
            x=colunas_escolhidas[0], 
            y=colunas_escolhidas[1], 
            color=df.loc[df_filtrado.index, "Cluster_KMeans"], title="Clusters de alunos (KMeans)" 
        ) 
        st.plotly_chart(fig_clusters, use_container_width=True)

        st.info(
            "ü§ñ **Interpreta√ß√£o do algoritmo K-Means:**\n"
            "- O K-Means √© um m√©todo de **clusteriza√ß√£o n√£o supervisionada**, que agrupa alunos com base em similaridades nas notas das disciplinas.\n"
            "- Cada ponto (aluno) √© atribu√≠do a um grupo cujo centro (centr√≥ide) representa o padr√£o m√©dio de desempenho daquele cluster.\n"
            "- Os grupos formados indicam perfis de estudantes com caracter√≠sticas semelhantes, como desempenho equilibrado, alta nota em exatas, ou dificuldades espec√≠ficas em uma √°rea.\n"
            "- A quantidade de clusters (K) √© definida previamente, permitindo comparar diferentes segmenta√ß√µes.\n"
            "- Essa an√°lise ajuda a entender **padr√µes de aprendizado e diferencia√ß√£o entre perfis de alunos**, auxiliando em estrat√©gias pedag√≥gicas mais direcionadas."
        )
        
        # ========================
        # DBSCAN
        # ========================
        st.subheader("üß© DBSCAN - Agrupamento por densidade")
        eps = st.slider("eps - Raio m√°ximo de vizinhan√ßa", 0.1, 5.0, 1.0, 0.1)
        min_samples = st.slider("min_samples - Exemplos m√≠nimos a serem considerados", 1, 20, 5)

        st.info(
            "**Explica√ß√£o sobre a parametriza√ß√£a do algoritmo:**\n"
            "1. O algoritmo escolhe um ponto qualquer.\n"
            "2. Cria uma 'bolha' de raio **eps** ao redor dele.\n"
            "3. Se dentro dessa 'bolha' houver ao menos **min_samples** pontos, ent√£o o ponto √© considerado um core point e forma um cluster.\n"
            "4. Se n√£o houver, o ponto pode ser classificado como border point (se estiver pr√≥ximo de um core point) ou como noise, ou ru√≠do (se n√£o pertencer a cluster nenhum)."
        )
        
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        clusters_dbscan = dbscan.fit_predict(X_scaled)

        df_filtrado["Cluster_DBSCAN"] = clusters_dbscan.astype(str)

        st.write("### Resultado DBSCAN")
        fig_dbscan = px.scatter(
            df_filtrado,
            x=colunas_escolhidas[0],
            y=colunas_escolhidas[1],
            color="Cluster_DBSCAN",
            title="Clusters DBSCAN"
        )
        st.plotly_chart(fig_dbscan, use_container_width=True)

        st.info(
            "üß© **Interpreta√ß√£o do algoritmo DBSCAN:**\n"
            "- O DBSCAN √© um algoritmo de **clusteriza√ß√£o baseada em densidade**, que identifica grupos de alunos de acordo com a concentra√ß√£o dos dados ‚Äî sem precisar definir o n√∫mero de clusters previamente.\n"
            "- Ele √© capaz de detectar **grupos de comportamento at√≠pico** (como alunos com desempenho muito alto ou muito baixo) e tamb√©m **outliers**, que n√£o se encaixam bem em nenhum padr√£o.\n"
            "- Os clusters representam regi√µes de alta densidade de alunos com notas semelhantes, enquanto os pontos ruidosos indicam casos excepcionais.\n"
            "- Essa abordagem √© √∫til quando os grupos t√™m formas irregulares ou tamanhos diferentes, oferecendo uma vis√£o mais flex√≠vel dos padr√µes de desempenho."
        )

        # ========================
        # SOM
        # ========================
        st.subheader("üß† Self-Organizing Map (SOM)")
        grid_x = st.slider("Tamanho do SOM (x)", 2, 10, 3)
        grid_y = st.slider("Tamanho do SOM (y)", 1, 10, 1)

        som = MiniSom(grid_x, grid_y, X_scaled.shape[1], sigma=1.0, learning_rate=0.5)
        som.random_weights_init(X_scaled)
        som.train_random(X_scaled, 500)

        clusters_som = []
        for x in X_scaled:
            w = som.winner(x)
            clusters_som.append(str(w))
        df_filtrado["Cluster_SOM"] = clusters_som

        fig_som = px.scatter(
            df_filtrado,
            x=colunas_escolhidas[0],
            y=colunas_escolhidas[1],
            color="Cluster_SOM",
            title="Clusters SOM"
        )
        st.plotly_chart(fig_som, use_container_width=True)

        st.info(
            "üß† **Interpreta√ß√£o do algoritmo SOM (Self-Organizing Map):**\n"
            "- O SOM √© uma **rede neural n√£o supervisionada** que projeta dados multidimensionais (como notas em v√°rias disciplinas) em um mapa bidimensional.\n"
            "- Cada c√©lula do mapa representa um grupo de alunos com padr√µes semelhantes de desempenho.\n"
            "- A disposi√ß√£o espacial dos grupos no mapa reflete **rela√ß√µes de similaridade**: c√©lulas pr√≥ximas indicam alunos com perfis de notas parecidos.\n"
            "- Regi√µes do mapa mais distantes representam perfis distintos, como grupos com alto desempenho em exatas versus linguagens.\n"
            "- Essa t√©cnica permite visualizar de forma intuitiva **como os alunos se distribuem em diferentes perfis de aprendizagem** e identificar gradientes de desempenho entre os grupos."
        )

        # ========================
        # COMBINADO DBSCAN + SOM
        # ========================
        st.write("### Compara√ß√£o DBSCAN + SOM")
        fig_combinado = px.scatter(
            df_filtrado,
            x=colunas_escolhidas[0],
            y=colunas_escolhidas[1],
            color="Cluster_DBSCAN",   # cor pelo DBSCAN
            symbol="Cluster_SOM",     # s√≠mbolo pelo SOM
            title="Clusters DBSCAN (cores) + SOM (s√≠mbolos)"
        )
        st.plotly_chart(fig_combinado, use_container_width=True)

        # ========================
        # MATRIZ DE COMPARA√á√ÉO
        # ========================
        st.write("### Matriz de Compara√ß√£o entre Kmeans e SOM")
        matriz_comparacao = pd.crosstab(df["Cluster_KMeans"], df_filtrado["Cluster_SOM"])
        st.dataframe(matriz_comparacao)

        # Heatmap da matriz
        fig_heatmap = px.imshow(
            matriz_comparacao,
            text_auto=True,
            color_continuous_scale="Blues",
            title="Heatmap da Compara√ß√£o Kmeans x SOM"
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)

       # ============================== 
        # PCA - Redu√ß√£o de Dimensionalidade 
        # ============================== 
        st.subheader("üìâ PCA - Visualiza√ß√£o em 2D")

        # Executar o PCA sobre as notas
        pca = PCA(n_components=2)
        pca_resultado = pca.fit_transform(colunas_notas)

        # Vari√¢ncia explicada
        var_exp = pca.explained_variance_ratio_ * 100
        st.write(f"### Vari√¢ncia explicada: PC1 = {var_exp[0]:.2f}% | PC2 = {var_exp[1]:.2f}%")

        # Adicionar resultados ao DataFrame
        df_pca = pd.DataFrame(pca_resultado, columns=["PC1", "PC2"])
        if "Cluster_KMeans" in df.columns:
            df_pca["Cluster_KMeans"] = df["Cluster_KMeans"].astype(str)
        else:
            df_pca["Cluster_KMeans"] = "0"

        # Gr√°fico PCA 2D
        st.write("### Redu√ß√£o de dimensionalidade (PCA)")
        fig_pca = px.scatter(
            df_pca,
            x="PC1",
            y="PC2",
            color="Cluster_KMeans",
            title="Visualiza√ß√£o dos clusters ap√≥s PCA (2 componentes principais)"
        )
        st.plotly_chart(fig_pca, use_container_width=True)

        # ========================
        # Gr√°ficos de contribui√ß√£o (loadings)
        # ========================
        st.write("### Contribui√ß√£o das vari√°veis nos componentes principais")

        # C√°lculo dos loadings
        loadings = pca.components_.T * np.sqrt(pca.explained_variance_)

        # PC1
        fig_loadings1 = px.bar(
            x=colunas_notas.columns,
            y=np.abs(loadings[:, 0]),
            title="Contribui√ß√£o das vari√°veis no PC1",
            labels={"x": "Vari√°vel", "y": "Contribui√ß√£o (|loading|)"}
        )
        st.plotly_chart(fig_loadings1, use_container_width=True)

        # PC2
        fig_loadings2 = px.bar(
            x=colunas_notas.columns,
            y=np.abs(loadings[:, 1]),
            title="Contribui√ß√£o das vari√°veis no PC2",
            labels={"x": "Vari√°vel", "y": "Contribui√ß√£o (|loading|)"}
        )
        st.plotly_chart(fig_loadings2, use_container_width=True)

        # Explica√ß√£o textual sobre o PCA
        st.info(
            "üìâ **Interpreta√ß√£o do PCA (An√°lise de Componentes Principais):**\n"
            "- O PCA reduz o conjunto de vari√°veis originais (as notas das disciplinas) para dois componentes principais (PC1 e PC2), que explicam a maior parte da variabilidade dos dados.\n"
            "- Cada ponto no gr√°fico representa um aluno, projetado nas dimens√µes que melhor sintetizam as diferen√ßas de desempenho.\n"
            "- As cores representam os clusters identificados (ex: via KMeans), permitindo observar se h√° grupos bem separados ou sobrepostos.\n"
            "- As barras dos gr√°ficos de contribui√ß√£o mostram o quanto cada disciplina influencia em cada componente principal.\n"
            "- Disciplinas com maior contribui√ß√£o em um componente indicam √°reas que mais ajudam a diferenciar o desempenho dos estudantes ‚Äî por exemplo, se Matem√°tica e Ci√™ncias da Natureza dominam o PC1, isso sugere que essas notas explicam melhor a varia√ß√£o global do desempenho.\n"
            "- Essa an√°lise permite compreender **quais √°reas s√£o mais determinantes para o desempenho geral** e pode orientar estrat√©gias pedag√≥gicas mais focadas."
        )

        st.markdown("---")

        st.subheader("üí° Esbo√ßo de diagn√≥stico")
        st.info(
            "- Analisando as sa√≠das do **RandomForest** e os gr√°ficos √† pop√≥sito das **Contribui√ß√µes no PC1 e PC2**, temos que as notas em reda√ß√£o e matem√°tica s√£o as que mais destoam em rela√ß√£o √† m√©dia da somat√≥riaa das notas, n√£o obstante sejam as mais determinantes para o desempenho geral.\n"
            "- Ao se comparar, por exemplo, as notas de reda√ß√£o no eixo x e de ci√™ncias humanas no eixo y, notam-se pontos mais difusos no quadrante superior direito (notas altas e ambas as provas) e quatro pontos no quadrante superior esquerdo (notas altas no eixo y, mas baixas no eixo x)\n"
            "- Isso indica que uma troca pedag√≥gica entre os professores de ci√™ncias humanas e o professor de reda√ß√£o pode ser muito ben√©fica a este √∫ltimo."
        )

    else:
        st.warning("Selecione pelo menos duas colunas num√©ricas para rodar a an√°lise.")